# -*- coding: utf-8 -*-
"""Image Classification Model Deployment .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fecxQUlv0aWxA54rUqmt0rWB2PmRYWHC
"""

import os
os.environ['KAGGLE_USERNAME'] = "xxxxxxxxxxx"
os.environ['KAGGLE_KEY'] = "xxxxxxxxxxx"

!kaggle datasets download -d alexattia/the-simpsons-characters-dataset

!mkdir thesimp
!unzip -qq the-simpsons-characters-dataset.zip -d thesimp
!ls thesimp

!ls thesimp/simpsons_dataset/simpsons_dataset/

import os

thesimp = os.path.join('/content/thesimp/simpsons_dataset/simpsons_dataset')

print(os.listdir(thesimp))

import shutil

ignore_simp = ['sideshow_mel', 'snake_jailbird', 'mayor_quimby', 'miss_hoover', 'professor_john_frink', 'otto_mann', 'troy_mcclure', 'nelson_muntz', 'apu_nahasapeemapetilon', 'waylon_smithers', 'rainier_wolfcastle', 'sideshow_bob', 'selma_bouvier', 'martin_prince', 'maggie_simpson', 'ralph_wiggum', 'agnes_skinner', 'barney_gumble', 'carl_carlson', 'cletus_spuckler', 'comic_book_guy', 'disco_stu', 'edna_krabappel', 'fat_tony', 'gil', 'groundskeeper_willie', 'kent_brockman', 'lenny_leonard','lionel_hutz' ]

for x in ignore_simp:
  path = os.path.join(thesimp, x)
  shutil.rmtree(path)

list_thesimp = os.listdir(thesimp)
print(list_thesimp)

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    rescale=1/255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2   
)

data_train = train_datagen.flow_from_directory(
    thesimp,
    target_size=(150, 150),
    batch_size=256,
    class_mode='categorical',
    subset='training')

data_val = train_datagen.flow_from_directory(
    thesimp, 
    target_size=(150, 150),
    batch_size=256,
    class_mode='categorical',
    subset='validation')

import tensorflow as tf

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.2), 
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(13, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics = ['accuracy'])

accuracy_threshold = 98e-2
class my_callbacks(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs = None):
        if logs.get('accuracy') >= accuracy_threshold:
            print('\nUntuk Epoch', epoch, '\nAkurasi mencapai = %2.2f%%' %(logs['accuracy']*100), 'training telah berhenti')
            self.model.stop_training = True

history = model.fit(
    data_train,
    steps_per_epoch = 40,
    epochs = 50,
    validation_data = data_val,
    validation_steps = 5,
    verbose = 2,
    callbacks = [my_callbacks()]
)

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

