# -*- coding: utf-8 -*-
"""Proyek 2 : Membuat Model Machine Learning dengan Data Time Series.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16G78M1GwY12JZ-U8l40PlU5OmWOjEhzU
"""

from google.colab import files # library untuk upload file
uploaded = files.upload()

import pandas as pd # library pandas

# import data
import io
data = pd.read_csv(io.BytesIO(uploaded['brazil_covid19.csv']))

# terdapat 12258 data
data.shape

data.head()

# menghapus kolom yang tidak digunakan, hendak menghitung jumlah kematian covid nya saja
data = data.drop(['region', 'state', 'cases'], axis=1)
data.head()

duplicate_rows_data = data[data.duplicated()]
print("jumlah duplikat data : ", duplicate_rows_data.shape)

"""ada duplikat data sebanyak 1132 data"""

data.count()

data = data.drop_duplicates()
data.head(5)

print(data.isnull().sum())

data.info()

data['date'] = pd.to_datetime(data.date)

data.info()

data.shape

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0,1))

normalisasi = scaler.fit_transform(data['deaths'].values.reshape(-1,1))
data['deaths'] = normalisasi
print(data)

import matplotlib.pyplot as plt

date = data['date'].values
death = data['deaths'].values

plt.figure(figsize = (20,10))
plt.plot(date, death)
plt.title('Jumlah Kematian Covid 19 di Brazil')

import tensorflow as tf
def windowedDataset(series, window_size, batch_size, shuffle_buffer):
  series = tf.expand_dims(series, axis = -1)
  ds = tf.data.Dataset.from_tensor_slices(series)
  ds = ds.window(window_size + 1, shift = 1, drop_remainder = True)
  ds = ds.flat_map(lambda w: w.batch(window_size + 1))
  ds = ds.shuffle(shuffle_buffer)
  ds = ds.map(lambda w: (w[:-1], w[-1:]))
  return ds.batch(batch_size).prefetch(1)

from sklearn.model_selection import train_test_split

xTrain, xTest, yTrain, yTest = train_test_split(death, date,
                                                test_size = 0.2,
                                                random_state = 0)


trainSet = windowedDataset(xTrain, window_size = 30, batch_size = 50, shuffle_buffer=1000)
valSet = windowedDataset(xTest, window_size = 30, batch_size = 50, shuffle_buffer=1000)

class Callback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae') < 0.10 and logs.get('val_mae') < 0.10):
      self.model.stop_training = True

callbacks = Callback()

def evalPlot(training):
  plt.style.use('seaborn')
  plt.figure(figsize = (8,6))

  plt.subplot(1,2,1)
  trainAcc = training.history['mae']
  valAcc = training.history['val_mae']
  epoch = range(len(trainAcc))
  trainAccPlot = plt.plot(epoch, trainAcc, 'r')
  valAccPlot = plt.plot(epoch, valAcc, 'b')
  plt.title('MAE training vs MAE Validasi')
  plt.legend(['Train MAE', 'Validation MAE'], loc=0)

  plt.subplot(1,2,2)
  trainLoss = training.history['loss']
  valLoss = training.history['val_loss']
  trainLossPlt = plt.plot(epoch, trainLoss, 'r')
  valLossPlt = plt.plot(epoch, valLoss, 'b')
  plt.title('Loss Training vs Loss Validasi')
  plt.legend(['Train Loss', 'Validation Loss'], loc=0)

from tensorflow.keras import layers

model = tf.keras.models.Sequential([

    tf.keras.layers.Bidirectional(layers.LSTM(60, return_sequences=True)),
    tf.keras.layers.Bidirectional(layers.LSTM(60)),
    tf.keras.layers.Dense(60, activation = 'tanh'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(30, activation = 'tanh'),
    tf.keras.layers.Dense(10, activation = 'tanh'),
    tf.keras.layers.Dense(1)
])

from tensorflow import keras
lrSchedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate = 1e-2,
    decay_steps=9000,
    decay_rate=0.9
)

optimizer = keras.optimizers.SGD(learning_rate = lrSchedule, momentum = 0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer = optimizer,
              metrics = ['mae'])

history = model.fit(trainSet, 
                    validation_data = valSet,
                    epochs = 100,
                    verbose = 2,
                    callbacks=[callbacks])

plt.plot(history.history['mae'], label='Training mae')
plt.plot(history.history['val_mae'], label='Validation mae')
plt.legend()

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()

