# -*- coding: utf-8 -*-
"""Proyek 1 : Membuat Model NLP dengan TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gRJIMHIlPFpj30NhXmZUEzdIbikx_KgS
"""

from google.colab import files #library untuk upload file
uploaded = files.upload()

import pandas as pd #library pandas

# Inisiasi directory tempat data akan dibaca
import io
data = pd.read_csv(io.BytesIO(uploaded['bbc-text.csv']))

data.head()

len(data) #terdapat 2225 sampel

data.shape #terdapat 2225 baris dan 2 kolom

import re #library regular expression

data['text-cleaned']=data.text.apply(lambda x: re.sub(r'[^A-Za-z]+',' ',x))

data['text-cleaned']=data['text-cleaned'].apply(lambda x: x.lower())

data['text-cleaned']=data['text-cleaned'].apply(lambda x:x.strip())

import nltk
from nltk.corpus import stopwords

stopwords=stopwords.words("english")

data['text-cleaned']=data['text-cleaned'].apply(lambda x : ' '.join([words for words in x.split() if words not in stopwords]))

print("Text sebelum dilakukan cleaning : {}".format(data.text[1]))

print("Text setelah dilakukan cleaning : {}".format(data['text-cleaned'][1]))

kategori = pd.get_dummies(data.category) #buat dummy dari kolom category yang terdiri dari 5 kategori yaitu business, entertainment, politics, sport dan tech 
new_data = pd.concat([data, kategori], axis=1) #dari dummy kategori digabungkan dengan data
new_data = new_data.drop(columns=['category','text']) #hapus kolom category dan text
new_data #data baru

kalimat = new_data['text-cleaned'].values
label = new_data[['business', 'entertainment', 'politics', 'sport', 'tech']].values

from sklearn.model_selection import train_test_split
sinopsis_latih, sinopsis_test, label_latih, label_test = train_test_split(kalimat, label, test_size=0.2)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(sinopsis_latih) 
tokenizer.fit_on_texts(sinopsis_test)
 
sekuens_latih = tokenizer.texts_to_sequences(sinopsis_latih)
sekuens_test = tokenizer.texts_to_sequences(sinopsis_test)
 
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(5, activation='softmax')
])

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

accuracy_threshold = 98e-2
class my_callbacks(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs = None):
        if logs.get('accuracy') >= accuracy_threshold:
            print('\nUntuk Epoch', epoch, '\nAkurasi mencapai = %2.2f%%' %(logs['accuracy']*100), 'training telah berhenti')
            self.model.stop_training = True

num_epochs = 20
history = model.fit(padded_latih, label_latih, epochs=num_epochs, 
                    validation_data=(padded_test, label_test), verbose=2, callbacks = [my_callbacks()])

import matplotlib.pyplot as plt


def plot_graphs(history, string):
  plt.plot(history.history[string])
  plt.plot(history.history['val_'+string])
  plt.xlabel("Epochs")
  plt.ylabel(string)
  plt.legend([string, 'val_'+string])
  plt.show()
  
plot_graphs(history, "accuracy")
plot_graphs(history, "loss")

